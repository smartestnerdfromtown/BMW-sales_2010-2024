{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    IntegerType,\n",
    "    DoubleType,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"BMW_Sales_Analysis_DEV\")\n",
    "    .config(\"spark.executor.memory\", \"4g\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "# Tip to reader: use WARN for development, ERROR in prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"model\", StringType(), nullable=False),\n",
    "        StructField(\"year\", IntegerType(), nullable=False),\n",
    "        StructField(\"region\", StringType(), nullable=False),\n",
    "        StructField(\"color\", StringType(), nullable=True),\n",
    "        StructField(\"fuel_type\", StringType(), nullable=True),\n",
    "        StructField(\"transmission\", StringType(), nullable=True),\n",
    "        StructField(\"engine_size_l\", DoubleType(), nullable=True),\n",
    "        StructField(\"mileage_km\", IntegerType(), nullable=True),\n",
    "        StructField(\"price_usd\", DoubleType(), nullable=False),\n",
    "        StructField(\"sales_volume\", IntegerType(), nullable=True),\n",
    "        StructField(\"sales_classification\", StringType(), nullable=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\n",
    "    path=\"dataset/BMW sales data (2010-2024).xls\",\n",
    "    schema=schema,\n",
    "    header=True,\n",
    "    mode=\"PERMISSIVE\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()  # number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- model: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- color: string (nullable = true)\n",
      " |-- fuel_type: string (nullable = true)\n",
      " |-- transmission: string (nullable = true)\n",
      " |-- engine_size_l: double (nullable = true)\n",
      " |-- mileage_km: integer (nullable = true)\n",
      " |-- price_usd: double (nullable = true)\n",
      " |-- sales_volume: integer (nullable = true)\n",
      " |-- sales_classification: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"BMW_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+--------+\n",
      "|       region|avg_price|num_cars|\n",
      "+-------------+---------+--------+\n",
      "|         Asia| 75554.93|    8454|\n",
      "|North America| 75070.05|    8335|\n",
      "|       Europe| 74988.36|    8334|\n",
      "|South America|  74973.6|    8251|\n",
      "|       Africa| 74885.77|    8253|\n",
      "|  Middle East| 74726.79|    8373|\n",
      "+-------------+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_price_per_region = spark.sql(\n",
    "    \"\"\"\n",
    "    select region, \n",
    "           round(avg(price_usd), 2) as avg_price,\n",
    "           count(*) as num_cars\n",
    "    from bmw_dataset\n",
    "    group by region\n",
    "    order by avg_price desc\n",
    "    \"\"\"\n",
    ")\n",
    "avg_price_per_region.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+----------+\n",
      "|   model|sales_volume|sales_rank|\n",
      "+--------+------------+----------+\n",
      "|7 Series|    23786466|         1|\n",
      "|      i8|    23423891|         2|\n",
      "|      X1|    23406060|         3|\n",
      "|3 Series|    23281303|         4|\n",
      "|      i3|    23133849|         5|\n",
      "|5 Series|    23097519|         6|\n",
      "|      M5|    22779688|         7|\n",
      "|      X3|    22745529|         8|\n",
      "|      X5|    22709749|         9|\n",
      "|      X6|    22661986|        10|\n",
      "|      M3|    22349694|        11|\n",
      "+--------+------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/25 16:34:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/25 16:34:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/25 16:34:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/25 16:34:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/25 16:34:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/25 16:34:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/25 16:34:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "top_selling_models = spark.sql(\n",
    "    \"\"\"\n",
    "    select model, \n",
    "           sum(sales_volume) as sales_volume,\n",
    "           rank() over(order by sum(sales_volume) desc) as sales_rank\n",
    "    from bmw_dataset\n",
    "    group by model\n",
    "    order by sales_rank\n",
    "    \"\"\"\n",
    ")\n",
    "top_selling_models.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|fuel_type|no_of_cars|\n",
      "+---------+----------+\n",
      "|   Hybrid|     12716|\n",
      "|   Petrol|     12550|\n",
      "| Electric|     12471|\n",
      "|   Diesel|     12263|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_by_fuel_type = spark.sql(\n",
    "    \"\"\"\n",
    "    select fuel_type,\n",
    "           count(model) as no_of_cars\n",
    "    from bmw_dataset\n",
    "    where fuel_type is not null\n",
    "    group by fuel_type\n",
    "    order by no_of_cars desc\n",
    "    \"\"\"\n",
    ")\n",
    "count_by_fuel_type.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+-------------+------+---------+------------+-------------+----------+---------+------------+--------------------+----------+\n",
      "|   Model|Year|       Region| Color|Fuel_Type|Transmission|Engine_Size_L|Mileage_KM|Price_USD|Sales_Volume|Sales_Classification|price_rank|\n",
      "+--------+----+-------------+------+---------+------------+-------------+----------+---------+------------+--------------------+----------+\n",
      "|      X3|2021|  Middle East| Black|   Diesel|      Manual|          3.8|    169642|    39999|        5319|                 Low|         1|\n",
      "|5 Series|2011|       Europe| White| Electric|      Manual|          4.7|    103523|    39997|        8048|                High|         2|\n",
      "|      X5|2013|       Europe|  Blue|   Hybrid|      Manual|          3.7|    132002|    39993|        9070|                High|         3|\n",
      "|7 Series|2017|  Middle East|  Blue|   Diesel|   Automatic|          4.5|    135422|    39992|        6711|                 Low|         4|\n",
      "|7 Series|2010|South America|Silver|   Petrol|   Automatic|          2.3|    134526|    39991|        3258|                 Low|         5|\n",
      "+--------+----+-------------+------+---------+------------+-------------+----------+---------+------------+--------------------+----------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/25 16:37:48 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/25 16:37:48 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/25 16:37:48 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/25 16:37:48 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/25 16:37:48 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "high_mil_low_price = spark.sql(\n",
    "    \"\"\"\n",
    "    select *, \n",
    "           rank() over(order by price_usd desc) as price_rank\n",
    "    from bmw_dataset\n",
    "    where mileage_km >= 100000 \n",
    "          and\n",
    "          price_usd <= 40000 \n",
    "    order by price_usd desc\n",
    "    \"\"\"\n",
    ")\n",
    "high_mil_low_price.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+----------+----------+\n",
      "|       region|manuals|automatics|total_cars|\n",
      "+-------------+-------+----------+----------+\n",
      "|       Europe|   4217|      4117|      8334|\n",
      "|       Africa|   4132|      4121|      8253|\n",
      "|North America|   4163|      4172|      8335|\n",
      "|South America|   4218|      4033|      8251|\n",
      "|  Middle East|   4228|      4145|      8373|\n",
      "|         Asia|   4196|      4258|      8454|\n",
      "+-------------+-------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transmission_distr_per_region = spark.sql(\n",
    "    \"\"\"\n",
    "    select region, \n",
    "           sum(case when transmission = 'Manual' then 1 else 0 end) as manuals,\n",
    "           sum(case when transmission = 'Automatic' then 1 else 0 end) as automatics,\n",
    "           count(*) as total_cars\n",
    "    from bmw_dataset\n",
    "    group by region    \n",
    "    \"\"\"\n",
    ")\n",
    "transmission_distr_per_region.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+---------------+--------+\n",
      "|fuel_type|year|avg_engine_size|num_cars|\n",
      "+---------+----+---------------+--------+\n",
      "|   Diesel|2015|           3.31|     803|\n",
      "| Electric|2015|           3.18|     826|\n",
      "|   Hybrid|2015|           3.27|     869|\n",
      "|   Petrol|2015|           3.23|     860|\n",
      "|   Diesel|2016|           3.22|     842|\n",
      "+---------+----+---------------+--------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "engine_size_analysis = spark.sql(\n",
    "    \"\"\"\n",
    "    select fuel_type,\n",
    "        cast(year as int) as year,\n",
    "        round(avg(cast(engine_size_l as double)), 2) as avg_engine_size,\n",
    "        count(*) as num_cars\n",
    "    from bmw_dataset\n",
    "    where cast(year as int) >= 2015\n",
    "    group by fuel_type, cast(year as int)\n",
    "    order by year asc, fuel_type\n",
    "    \"\"\"\n",
    ")\n",
    "engine_size_analysis.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I group by both fuel_type and year, I am expected to get multiple rows per year (one per fuel type). If you want only one row per year, you need to drop `fuel_type` from group by.\n",
    "\n",
    "Besides this, I also have casted them to double and integers. I had already provided schema, but who knows what can happen?:) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+------------+\n",
      "|       region| color|no_of_models|\n",
      "+-------------+------+------------+\n",
      "|       Europe| Black|        1473|\n",
      "|North America|   Red|        1461|\n",
      "|         Asia| Black|        1460|\n",
      "|North America|Silver|        1435|\n",
      "|  Middle East|  Grey|        1429|\n",
      "+-------------+------+------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "popular_color_per_region = spark.sql(\n",
    "    \"\"\"\n",
    "    select region, color, count(model) no_of_models\n",
    "    from bmw_dataset\n",
    "    group by region, color\n",
    "    order by no_of_models desc\n",
    "\"\"\"\n",
    ")\n",
    "popular_color_per_region.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+\n",
      "|year|sales_volume|\n",
      "+----+------------+\n",
      "|2022|    17920946|\n",
      "|2024|    17527854|\n",
      "|2019|    17191956|\n",
      "|2015|    17010207|\n",
      "|2014|    16958960|\n",
      "+----+------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "yearly_sales = spark.sql(\n",
    "    \"\"\"\n",
    "    select year, sum(sales_volume) as sales_volume\n",
    "    from bmw_dataset\n",
    "    group by year\n",
    "    order by sales_volume desc\n",
    "    \"\"\"\n",
    ")\n",
    "yearly_sales.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, I finally understood that the data is **synthetic/unrealistic.** You can still analyze relative trends (which models sell more vs less in your dataset, how averages change by year, etc.), but donâ€™t treat the absolute numbers as real-world BMW sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+\n",
      "|   model|mileage_km|price_usd|\n",
      "+--------+----------+---------+\n",
      "|      i8|    115320|   119998|\n",
      "|      i8|    163849|   119997|\n",
      "|      X6|    142419|   119997|\n",
      "|      X1|    172950|   119996|\n",
      "|3 Series|     12264|   119994|\n",
      "|      i8|     26622|   119992|\n",
      "|      X6|     27540|   119988|\n",
      "|5 Series|    181043|   119988|\n",
      "|      X1|    146281|   119988|\n",
      "|      X6|     95648|   119986|\n",
      "+--------+----------+---------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "price_vs_mileage_corr = spark.sql(\n",
    "    \"\"\"\n",
    "    select model, mileage_km, price_usd\n",
    "    from bmw_dataset\n",
    "    order by price_usd desc\n",
    "    \"\"\"\n",
    ")\n",
    "price_vs_mileage_corr.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between mileage and price: -0.00423819457462334\n"
     ]
    }
   ],
   "source": [
    "price_vs_mileage_corr = df.stat.corr(\"mileage_km\", \"price_usd\")\n",
    "print(\"Correlation between mileage and price:\", price_vs_mileage_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Close to -1 --> strong negative correlation (higher mileage --> lower price) which is quite **realistic**.\n",
    "- Close to 0 --> no relationship.\n",
    "- Close to +1 --> strong positive correlation (rare for price vs mileage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+---------+-------+\n",
      "|       region|   model|price_usd|ranking|\n",
      "+-------------+--------+---------+-------+\n",
      "|       Africa|      i8|   119997|      1|\n",
      "|       Africa|      X1|   119996|      2|\n",
      "|       Africa|      X6|   119988|      3|\n",
      "|       Africa|      X1|   119988|      3|\n",
      "|         Asia|      X6|   119997|      1|\n",
      "|         Asia|5 Series|   119988|      2|\n",
      "|         Asia|7 Series|   119978|      3|\n",
      "|       Europe|      i8|   119985|      1|\n",
      "|       Europe|5 Series|   119981|      2|\n",
      "|       Europe|      X1|   119961|      3|\n",
      "|  Middle East|      i8|   119998|      1|\n",
      "|  Middle East|3 Series|   119994|      2|\n",
      "|  Middle East|5 Series|   119978|      3|\n",
      "|North America|      i8|   119992|      1|\n",
      "|North America|3 Series|   119970|      2|\n",
      "|North America|5 Series|   119963|      3|\n",
      "|South America|      X6|   119986|      1|\n",
      "|South America|3 Series|   119982|      2|\n",
      "|South America|      X6|   119981|      3|\n",
      "+-------------+--------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ranking_expensiv_cars = spark.sql(\n",
    "    \"\"\"\n",
    "    select *\n",
    "    from (\n",
    "        select region,\n",
    "               model,\n",
    "               price_usd,\n",
    "               dense_rank() over (partition by region order by price_usd desc) as ranking\n",
    "        from bmw_dataset\n",
    "    ) t\n",
    "    where ranking <= 3\n",
    "    order by region, ranking\n",
    "    \"\"\"\n",
    ")\n",
    "ranking_expensiv_cars.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+------------+\n",
      "|   model|year|year_ranking|\n",
      "+--------+----+------------+\n",
      "|3 Series|2024|           1|\n",
      "|5 Series|2024|           1|\n",
      "|7 Series|2024|           1|\n",
      "|      M3|2024|           1|\n",
      "|      M5|2024|           1|\n",
      "|      X1|2024|           1|\n",
      "|      X3|2024|           1|\n",
      "|      X5|2024|           1|\n",
      "|      X6|2024|           1|\n",
      "|      i3|2024|           1|\n",
      "|      i8|2024|           1|\n",
      "+--------+----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recent_car_per_model = spark.sql(\n",
    "    \"\"\"\n",
    "    select * from (\n",
    "        select distinct model, \n",
    "            year,\n",
    "            rank() over(partition by model order by year desc) \n",
    "                            as year_ranking\n",
    "        from bmw_dataset) t\n",
    "    where year_ranking = 1\n",
    "    \"\"\"\n",
    ")\n",
    "recent_car_per_model.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will try to find all cars whose `Price_USD` is above the overall average price of all cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+---------+\n",
      "|   model|year|price_usd|\n",
      "+--------+----+---------+\n",
      "|3 Series|2012|   117995|\n",
      "|3 Series|2023|    86402|\n",
      "|3 Series|2010|    86660|\n",
      "|3 Series|2020|    78509|\n",
      "|3 Series|2017|    86684|\n",
      "|3 Series|2020|    79774|\n",
      "|3 Series|2024|   113482|\n",
      "|3 Series|2019|   108637|\n",
      "|3 Series|2024|    79650|\n",
      "|3 Series|2012|    96429|\n",
      "|3 Series|2013|   101189|\n",
      "|3 Series|2022|   107968|\n",
      "|3 Series|2023|    84635|\n",
      "|3 Series|2015|    89156|\n",
      "|3 Series|2021|    87186|\n",
      "|3 Series|2017|   100678|\n",
      "|3 Series|2023|   101460|\n",
      "|3 Series|2021|   112265|\n",
      "|3 Series|2012|    99478|\n",
      "|3 Series|2017|   115369|\n",
      "+--------+----+---------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "above_average = spark.sql(\n",
    "    \"\"\"\n",
    "    select model, year, price_usd\n",
    "    from (\n",
    "           select *, \n",
    "                avg(price_usd) over(partition by model) as avg_price\n",
    "           from bmw_dataset \n",
    "    ) t\n",
    "    where price_usd > avg_price\n",
    "    \"\"\"\n",
    ")\n",
    "above_average.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "| color|\n",
      "+------+\n",
      "|Silver|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "second_most_popular_color = spark.sql(\n",
    "    \"\"\"\n",
    "    select color\n",
    "    from (\n",
    "        select color,\n",
    "            rank() over(order by count(model) desc) as rank\n",
    "        from bmw_dataset\n",
    "        group by color\n",
    "    ) t\n",
    "    where rank = 2\n",
    "    \"\"\"\n",
    ")\n",
    "second_most_popular_color.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
